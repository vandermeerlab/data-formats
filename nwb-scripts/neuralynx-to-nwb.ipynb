{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initial attempt at NWB conversion for NeuraLynx data following \"manual\" conversion described in https://pynwb.readthedocs.io/en/stable/tutorials/domain/ecephys.html .  Unlike the example(s) there I (Yarik) was trying to identify levels of data and metadata to consider, and also to store them across multiple .nwb files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pynwb\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from pynwb import NWBFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common lab wide metadata\n",
    "lab_metadata = dict(\n",
    "    lab=\"MVDMLab\",\n",
    "    institution=\"Dartmouth College\",\n",
    "    keywords=[\"DANDI Pilot\"], # arbitrary, so let's promote!\n",
    ")\n",
    "# Experiment specific one\n",
    "experiment_metadata = dict(\n",
    "    experimenter=\"Jimmie Gmaz <jim.gmaz@gmail.com>\",  # Let's see if nwb can swallow such a record ;)\n",
    "    experiment_description=\"Whatever Jimmi did and why\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata which is likely to come from data files and \"promotion\" metadata records\n",
    "\n",
    "# Most likely many could be parsed from the filenames which are likely to encode some of it\n",
    "# So \"heuristical\" converter could establish metadata harvesting from the filenames\n",
    "\n",
    "#\n",
    "# Session specific\n",
    "session_metadata = dict(\n",
    "    session_id=\"TODO\",\n",
    "    session_description=\"TODO\",  # args[0] in nwbfile\n",
    "    session_start_time=datetime.now(tzlocal()), # TEMP  # args[2] in nwbfile; TODO needs to be datetime\n",
    ")\n",
    "subject_metadata = dict(\n",
    "    subject_id=\"TODO\",\n",
    "    weight=\"TODO\",\n",
    "    age=\"TODO\",  # duplicate with session_start_time and date_of_birth but why not?\n",
    "    species=\"Mus musculus\",\n",
    "    sex=\"TODO\",\n",
    "    date_of_birth=datetime.now(tzlocal()), # TEMP: TODO\n",
    ")\n",
    "surgery_metadata = dict(\n",
    "    surgery=\"TODO: Narrative description about surgery/surgeries, including date(s) and who performed surgery.\"\n",
    ")\n",
    "# Actually probably only \"identifier\" should be file specific, the rest common across files\n",
    "# we would like to produce: separate for .ncs, .ntt, behavioral metadata, etc\n",
    "file_metadata = dict(\n",
    "    source_script=\"somescript-not-clear-whyneeds to be not empty if file_name is provided\",\n",
    "    source_script_file_name=\"TODO\", # __file__,\n",
    ")\n",
    "\n",
    "# common filename prefix - let's mimic DANDI filenaming convention right away\n",
    "filename_prefix = \"sub-{subject_id}_ses-{session_id}\".format(**subject_metadata, **session_metadata)\n",
    "# the rest will be specific to the corresponding file. E.g. we will have separate\n",
    "#  - `_probe-<name>_ecephys.nwb` (from each .ncs) - contineous data from each tetrode. probably chunked and compressed\n",
    "#  - `_???_ecephys.nwb` (from each .ntt) - spike detected windowed data. \n",
    "#  - `_behav.mpg` + `_behav.nwb` - video recording and metadata (including those .png?) for behavior component within experiment recording session\n",
    "# Pretty much we need to establish a framework where EVERY file present would be\n",
    "# provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below would need to follow common pattern \n",
    "- create a new NWBFile with common metadata,\n",
    "- populate with relevant data and metadata\n",
    "- save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such NWBFile will be created for each separate file, and then fill up with the corresponding\n",
    "#\n",
    "filename_suffix = \"TODO\"\n",
    "nwbfile = NWBFile(\n",
    "    identifier=\"{}_{}\".format(filename_prefix, filename_suffix), # args[1] in nwbfile, may be just UUID? not sure why user has to provide it really\n",
    "    subject=pynwb.file.Subject(**subject_metadata),\n",
    "    **lab_metadata,\n",
    "    **experiment_metadata,\n",
    "    **session_metadata,\n",
    "    **surgery_metadata,\n",
    "    **file_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-TODO_ses-TODO_TODO\n"
     ]
    }
   ],
   "source": [
    "print(nwbfile.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy/pasted example - yet to be tuned for data at hands.\n",
    "# Most likely we would want to establish Neo-based \"sweep and convert\".\n",
    "# but somehow need to ensure that we had not forgotten any piece of data/file.\n",
    "device = nwbfile.create_device(name='trodes_rig123')\n",
    "\n",
    "electrode_name = 'tetrode1'\n",
    "description = \"an example tetrode\"\n",
    "location = \"somewhere in the hippocampus\"\n",
    "\n",
    "electrode_group = nwbfile.create_electrode_group(electrode_name,\n",
    "                                                 description=description,\n",
    "                                                 location=location,\n",
    "                                                 device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save the generated file\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "# TODO: I think we should right away use dandi-cli provided API to create the filename based on metadata\n",
    "# in the NWBFile\n",
    "with NWBHDF5IO('ecephys_example.nwb', 'w') as io:\n",
    "    io.write(nwbfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default available)",
   "language": "python",
   "name": "default-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
