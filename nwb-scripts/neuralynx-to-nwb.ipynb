{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An initial attempt at NWB conversion for NeuraLynx data following \"manual\" conversion described in https://pynwb.readthedocs.io/en/stable/tutorials/domain/ecephys.html .  Unlike the example(s) there I (Yarik) was trying to identify levels of data and metadata to consider, and also to store them across multiple .nwb files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pynwb\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from pynwb import NWBFile\n",
    "\n",
    "import neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = '../data/BiconditionalOdor/M040-2020-04-28-CDOD11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common lab wide metadata\n",
    "lab_metadata = dict(\n",
    "    lab=\"MVDMLab\",\n",
    "    institution=\"Dartmouth College\",\n",
    "    keywords=[\"DANDI Pilot\"], # arbitrary, so let's promote!\n",
    ")\n",
    "# Experiment specific one\n",
    "experiment_metadata = dict(\n",
    "    experimenter=\"Jimmie Gmaz <jim.gmaz@gmail.com>\",  # Let's see if nwb can swallow such a record ;)\n",
    "    experiment_description=\"Contextual odor discrimination task\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralynxIO: /Users/jimmiegmaz/Desktop/M040-2020-04-28-CDOD11\n",
      "nb_block: 1\n",
      "nb_segment:  [1]\n",
      "signal_channels: []\n",
      "unit_channels: [chTT2#27#0, chTT2#28#0, chTT2#11#0, chTT2#12#0, chTT4#31#0, chTT4#15#0, chTT4#9#0, chTT4#25#0]\n",
      "event_channels: [Events event_id=11 ttl=0, Events event_id=11 ttl=1, Events event_id=11 ttl=2, Events event_id=11 ttl=4 ... Events event_id=11 ttl=48 Events event_id=11 ttl=64 Events event_id=11 ttl=96 Events event_id=19 ttl=0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a reader\n",
    "reader = neo.io.NeuralynxIO(dirname=session_data) # TODO: newer version should support: , keep_original_times=True)\n",
    "reader.parse_header()\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2020-04-28',\n",
       " 'day_of_recording': '11',\n",
       " 'subject_id': 'M040',\n",
       " 'task': 'CDOD'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as op\n",
    "import re\n",
    "filename_metadata = re.match(\n",
    "    '(?P<subject_id>[A-Za-z0-9]*)-(?P<date>20..-..-..)-(?P<task>[A-Za-z]*)(?P<day_of_recording>[0-9]*)$',\n",
    "    op.basename(session_data)).groupdict()\n",
    "assert filename_metadata\n",
    "filename_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those time stamps are in sub-second and not the one we would want to the \"session time\"\n",
    "# time.gmtime(reader.get_event_timestamps()[0][0])\n",
    "# TODO: figure out where in this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: figure out what those timestamps in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse\n",
      "left\n",
      "vStr\n",
      "4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scans through Experimental Keys to extract relevant metadata for NWB file\n",
    "\n",
    "# name of ExpKeys file\n",
    "keys_name = session_data + '/'  + filename_metadata['subject_id'] + '_' + filename_metadata['date'].replace('-','_') + '_keys.m'\n",
    "\n",
    "# read session ExpKeys\n",
    "with open (keys_name, 'rt') as keys_file:\n",
    "    exp_keys = keys_file.read()\n",
    "\n",
    "# list of metadata to extract\n",
    "metadata_list = ['ExpKeys.species','ExpKeys.hemisphere','ExpKeys.weight','ExpKeys.probeDepth','ExpKeys.target']\n",
    "\n",
    "# initialize metadata dictionary\n",
    "metadata_keys = dict.fromkeys(metadata_list)\n",
    "\n",
    "# extract metadata\n",
    "for item in exp_keys.split(\"\\n\"):\n",
    "    for field in metadata_list:\n",
    "        if field in item:\n",
    "            metadata_keys[field] = re.search('(?<=\\=)(.*?)(?=\\;)', item).group(0).strip() \n",
    "            metadata_keys[field] = re.sub('[^A-Za-z0-9]+', '', metadata_keys[field])\n",
    "            print(metadata_keys[field])\n",
    "            \n",
    "# TODO: add surgery details to ExpKeys, including AP and ML coordinates, change probeDepth to mm,\n",
    "# add filtering, individual tetrode depth, tetrode referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata which is likely to come from data files and \"promotion\" metadata records\n",
    "\n",
    "# Most likely many could be parsed from the filenames which are likely to encode some of it\n",
    "# So \"heuristical\" converter could establish metadata harvesting from the filenames\n",
    "\n",
    "#\n",
    "# Session specific\n",
    "session_metadata = dict(\n",
    "    session_id=\"%(subject_id)s-%(date)s\" % filename_metadata,\n",
    "    session_description=\"Extracellular ephys recording in the left hemisphere of the nucleus accumbens\",  # args[0] in nwbfile\n",
    "    session_start_time=datetime.now(tzlocal()), # TEMP  # args[2] in nwbfile; TODO needs to be datetime\n",
    ")\n",
    "subject_metadata = dict(\n",
    "    subject_id=filename_metadata['subject_id'],\n",
    "    weight=metadata_keys['ExpKeys.weight'],\n",
    "    age=\"TODO\",  # duplicate with session_start_time and date_of_birth but why not?\n",
    "    species=metadata_keys['ExpKeys.species'],\n",
    "    sex=\"female\",\n",
    "#     hemisphere=metadata_keys['ExpKeys.hemisphere'],\n",
    "#     depth=metadata_keys['ExpKeys.probeDepth'],\n",
    "#     region=metadata_keys['ExpKeys.target'],\n",
    "    date_of_birth=datetime.now(tzlocal()), # TEMP: TODO\n",
    ")\n",
    "surgery_metadata = dict(\n",
    "    surgery=\"Headbar on xx/xx/2020, craniotomy over right hemisphere on xx/xx/2020, craniotomy over left hemisphere on xx/xx/2020. All surgeries performed by JG.\"\n",
    ")\n",
    "# Actually probably only \"identifier\" should be file specific, the rest common across files\n",
    "# we would like to produce: separate for .ncs, .ntt, behavioral metadata, etc\n",
    "file_metadata = dict(\n",
    "    source_script=\"somescript-not-clear-whyneeds to be not empty if file_name is provided\",\n",
    "    source_script_file_name=\"TODO\", # __file__,\n",
    ")\n",
    "\n",
    "# common filename prefix - let's mimic DANDI filenaming convention right away\n",
    "filename_prefix = \"sub-{subject_id}_ses-{session_id}\".format(**subject_metadata, **session_metadata)\n",
    "# the rest will be specific to the corresponding file. E.g. we will have separate\n",
    "#  - `_probe-<name>_ecephys.nwb` (from each .ncs) - contineous data from each tetrode. probably chunked and compressed\n",
    "#  - `_???_ecephys.nwb` (from each .ntt) - spike detected windowed data. \n",
    "#  - `_behav.mpg` + `_behav.nwb` - video recording and metadata (including those .png?) for behavior component within experiment recording session\n",
    "# Pretty much we need to establish a framework where EVERY file present would be\n",
    "# provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 'TODO',\n",
       " 'date_of_birth': datetime.datetime(2020, 8, 19, 7, 50, 52, 264817, tzinfo=tzlocal()),\n",
       " 'sex': 'female',\n",
       " 'species': 'Mouse',\n",
       " 'subject_id': 'M040',\n",
       " 'weight': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below would need to follow common pattern \n",
    "- create a new NWBFile with common metadata,\n",
    "- populate with relevant data and metadata\n",
    "- save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such NWBFile will be created for each separate file, and then fill up with the corresponding\n",
    "#\n",
    "filename_suffix = \"TODO\"\n",
    "nwbfile = NWBFile(\n",
    "    identifier=\"{}_{}\".format(filename_prefix, filename_suffix), # args[1] in nwbfile, may be just UUID? not sure why user has to provide it really\n",
    "    subject=pynwb.file.Subject(**subject_metadata),\n",
    "    **lab_metadata,\n",
    "    **experiment_metadata,\n",
    "    **session_metadata,\n",
    "    **surgery_metadata,\n",
    "    **file_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-M040_ses-M040-2020-04-28_TODO\n"
     ]
    }
   ],
   "source": [
    "print(nwbfile.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add electrode metadata\n",
    "# create probe device\n",
    "device = nwbfile.create_device(name='silicon probe', description='A4x2-tet-5mm-150-200-121', manufacturer='NeuroNexus')\n",
    "\n",
    "# for each channel on the probe\n",
    "for chl in reader.header['unit_channels']:\n",
    "    \n",
    "    # get tetrode id\n",
    "    tetrode = re.search('(?<=TT)(.*?)(?=#)', chl[0]).group(0)\n",
    "    electrode_name = 'tetrode' + tetrode\n",
    "    \n",
    "    # get channel id\n",
    "    channel = re.search('(?<=#)(.*?)(?=#)', chl[0]).group(0)\n",
    "           \n",
    "    if electrode_name not in nwbfile.electrode_groups: # make tetrode if does not exist\n",
    "    \n",
    "        description = electrode_name\n",
    "        location = metadata_keys['ExpKeys.hemisphere'] + ' ' + metadata_keys['ExpKeys.target'] + ' ' + \\\n",
    "            '(' + metadata_keys['ExpKeys.probeDepth'] + ' um)'\n",
    "\n",
    "        electrode_group = nwbfile.create_electrode_group(electrode_name,\n",
    "                                                         description=description,\n",
    "                                                         location=location,\n",
    "                                                         device=device)\n",
    "        \n",
    "    # add channel to tetrode\n",
    "    nwbfile.add_electrode(id=int(channel),\n",
    "                          x=-1.2, y=float(metadata_keys['ExpKeys.probeDepth']), z=-1.5,\n",
    "                          location=metadata_keys['ExpKeys.target'], filtering='none',\n",
    "                          imp = 0.0, group=nwbfile.electrode_groups[electrode_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add electrode data\n",
    "# copy and pasted example\n",
    "electrode_table_region = nwbfile.create_electrode_table_region([0, 2], 'the first and third electrodes')\n",
    "\n",
    "from pynwb.ecephys import ElectricalSeries\n",
    "\n",
    "rate = 10.0\n",
    "np.random.seed(1234)\n",
    "data_len = 1000\n",
    "ephys_data = np.random.rand(data_len * 2).reshape((data_len, 2))\n",
    "ephys_timestamps = np.arange(data_len) / rate\n",
    "\n",
    "ephys_ts = ElectricalSeries('test_ephys_data',\n",
    "                            ephys_data,\n",
    "                            electrode_table_region,\n",
    "                            timestamps=ephys_timestamps,\n",
    "                            # Alternatively, could specify starting_time and rate as follows\n",
    "                            # starting_time=ephys_timestamps[0],\n",
    "                            # rate=rate,\n",
    "                            resolution=0.001,\n",
    "                            comments=\"This data was randomly generated with numpy, using 1234 as the seed\",\n",
    "                            description=\"Random numbers generated with numpy.random.rand\")\n",
    "nwbfile.add_acquisition(ephys_ts)\n",
    "\n",
    "nwbfile.add_unit(id=1, electrodes=[0])\n",
    "nwbfile.add_unit(id=2, electrodes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated file\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "# TODO: I think we should right away use dandi-cli provided API to create the filename based on metadata\n",
    "# in the NWBFile\n",
    "with NWBHDF5IO('ecephys_example.nwb', 'w') as io:\n",
    "    io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
