{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:23:12 [I] klustakwik KlustaKwik2 version 0.2.6\n"
     ]
    }
   ],
   "source": [
    "# Recommended import aliases: https://spikeinterface.readthedocs.io/en/latest/getting_started/plot_getting_started.html\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "# Additional imports\n",
    "import os.path as op\n",
    "import neo  # neo for some direct reading to check on # of segments etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file1 = '/Users/manishm/Work/vanDerMeerLab/NWB/data/M40/CSC1.ncs'\n",
    "dname1 = (op.dirname(sample_file1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throws an errot if the the ncs files don't have the same length\n",
    "#On omitting the file with a different length, this works (M40-2020-04-28-CDOD11/CSC26.ncs for instance)\n",
    "reader1 = neo.NeuralynxIO(dirname=dname1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralynxIO: /Users/manishm/Work/vanDerMeerLab/NWB/data/M40\n",
      "nb_block: 1\n",
      "nb_segment:  [7]\n",
      "signal_channels: [CSC1, CSC10, CSC11, CSC13 ... CSC5 CSC7 CSC8 CSC9]\n",
      "unit_channels: []\n",
      "event_channels: []\n",
      "\n",
      "range(0, 7)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(reader1)\n",
    "print(range(reader1.segment_count(0)))\n",
    "print(reader1.block_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordingList = [se.NeuralynxRecordingExtractor(dirname=op.dirname(sample_file1), seg_index=i) for i in range(reader1.segment_count(0))]\n",
    "recordingFull = se.MultiRecordingTimeExtractor(recordingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__contains__', '__delitem__', '__getitem__', '__iadd__', '__imul__', '__iter__', '__len__', '__mul__', '__reversed__', '__rmul__', '__setitem__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "['__abstractmethods__', '__del__', '__dict__', '__module__', '__slots__', '__weakref__', '_abc_impl', '_cast_start_end_frame', '_channel_ids', '_default_filename', '_epochs', '_features', '_find_section_for_frame', '_find_section_for_time', '_first_recording', '_get_file_path', '_key_properties', '_kwargs', '_num_channels', '_num_frames', '_properties', '_recordings', '_sampling_frequency', '_start_frames', '_start_times', '_tmp_folder', 'add_epoch', 'allocate_array', 'check_if_dumpable', 'clear_channel_property', 'clear_channels_property', 'copy_channel_properties', 'dump_to_dict', 'dump_to_json', 'dump_to_pickle', 'frame_to_time', 'get_channel_gains', 'get_channel_groups', 'get_channel_ids', 'get_channel_locations', 'get_channel_property', 'get_channel_property_names', 'get_dtype', 'get_epoch', 'get_epoch_info', 'get_epoch_names', 'get_num_channels', 'get_num_frames', 'get_sampling_frequency', 'get_shared_channel_property_names', 'get_snippets', 'get_sub_extractors_by_property', 'get_tmp_folder', 'get_traces', 'id', 'is_dumpable', 'is_filtered', 'load_extractor_from_dict', 'load_extractor_from_json', 'load_extractor_from_pickle', 'load_probe_file', 'make_serialized_dict', 'recordings', 'remove_epoch', 'save_to_probe_file', 'set_channel_gains', 'set_channel_groups', 'set_channel_locations', 'set_channel_property', 'set_tmp_folder', 'time_to_frame', 'write_recording', 'write_to_binary_dat_format', 'write_to_h5_dataset_format']\n"
     ]
    }
   ],
   "source": [
    "l3 = dir(recordingList)\n",
    "l4 = dir(recordingFull)\n",
    "unique3 = [x for x in l3 if not (x in l4)]\n",
    "unique4 = [x for x in l4 if not (x in l3)]\n",
    "print(unique3)\n",
    "print(unique4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters\n",
      " {'adjacency_radius': None, 'threshold_strong_std_factor': 5, 'threshold_weak_std_factor': 2, 'detect_sign': -1, 'extract_s_before': 16, 'extract_s_after': 32, 'n_features_per_channel': 3, 'pca_n_waveforms_max': 10000, 'num_starting_clusters': 50}\n",
      "New parameters\n",
      " {'adjacency_radius': None, 'threshold_strong_std_factor': 5, 'threshold_weak_std_factor': 2, 'detect_sign': -1, 'extract_s_before': 8, 'extract_s_after': 24, 'n_features_per_channel': 8, 'pca_n_waveforms_max': 10000, 'num_starting_clusters': 50}\n"
     ]
    }
   ],
   "source": [
    "# Setting up parameters for Klusta\n",
    "neuralynx_prms = ss.get_default_params('klusta')\n",
    "print(\"Default parameters\\n\", neuralynx_prms)\n",
    "# Change parameters to match ntt format\n",
    "# @Matt, Can you take a look at this and see if it makes sense?\n",
    "neuralynx_prms['extract_s_before'] = 8\n",
    "neuralynx_prms['extract_s_after'] = 24\n",
    "neuralynx_prms['num_starting_clusters'] = 50\n",
    "neuralynx_prms['n_features_per_channel'] = 8\n",
    "print(\"New parameters\\n\", neuralynx_prms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it separately for each segment\n",
    "klustaOutList = [ss.run_klusta(recordingList[i], output_folder=\"klusta_test2/seg\" + str(i), **neuralynx_prms) for i in range(len(recordingList))]\n",
    "#Works and doesn't throw an error.\n",
    "#Will run it to completion later for comparison with Kilosort and other spike sorting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! No channel location given. Add dummy location.\n",
      "Skipping field: only int or float can be serialized\n",
      "Skipping field: only int or float can be serialized\n",
      "RUNNING SHELL SCRIPT: /Users/manishm/Work/vanDerMeerLab/NWB/hackathon/Github/data-formats/kilosort2_test/Attempt2/klusta_test/run_klusta.sh\n"
     ]
    }
   ],
   "source": [
    "#Run it on the concatenated segment\n",
    "klustaOutFull = ss.run_klusta(recordingFull, output_folder=\"klusta_test2/full\", **neuralynx_prms)\n",
    "#Works and doesn't throw an error.\n",
    "#Will run it to completion later for comparison with Kilosort and other spike sorting methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
