{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended import aliases: https://spikeinterface.readthedocs.io/en/latest/getting_started/plot_getting_started.html\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "# Additional imports\n",
    "import os.path as op\n",
    "import neo  # neo for some direct reading to check on # of segments etc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get manual clustering results using Hung-tu's code\n",
    "from loader_mclust import load_spikes\n",
    "file_path = 'data/BiconditionalOdor/M040-2020-04-29-CDOD12/'\n",
    "units = load_spikes(file_path)\n",
    "sampling_frequency = 30000\n",
    "\n",
    "# Let's concatenate all the units with unique per each unit labels\n",
    "# into numpy arrays and pass it all to NumpySortingExtractor\n",
    "all_times = []\n",
    "all_labels = []\n",
    "units_map = []\n",
    "for u_index, u in enumerate(units):\n",
    "    all_times += [u.time]\n",
    "    all_labels += [u_index] * len(u.time)\n",
    "    units_map.append(u.label)\n",
    "all_times = np.hstack(all_times)\n",
    "all_labels = np.hstack(all_labels)\n",
    "assert all_times.ndim == 1\n",
    "assert all_times.shape == all_labels.shape\n",
    "\n",
    "mclust_res = se.NumpySortingExtractor()\n",
    "mclust_res.set_times_labels(times=all_times, labels=all_labels )\n",
    "mclust_res.set_sampling_frequency(sampling_frequency=sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the results directory\n",
    "results_top_dir = 'data/Kilosort2_results/M040-2020-04-29-CDOD12/'\n",
    "subdirs = [os.path.join(results_top_dir, dirname) for dirname in os.listdir(results_top_dir) if os.path.isdir(os.path.join(results_top_dir,dirname))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through results to see if at least one unit matches\n",
    "first_pass_candidates = {}\n",
    "funny_business = {}\n",
    "max_agreement_scores = {}\n",
    "\n",
    "for dirname in subdirs:\n",
    "    # Using PhySortingExtractor because Kilosort2 results are exported in the Phy format\n",
    "    this_key = \"_\".join(dirname.split(\"_\")[-2:])\n",
    "    this_ksr = se.PhySortingExtractor(folder_path=dirname)\n",
    "    this_com = sc.compare_two_sorters(sorting1=this_ksr, sorting2=mclust_res)\n",
    "    #Saving this to see what kind of values pop out\n",
    "    max_agreement_scores[this_key] = this_com.agreement_scores.max()\n",
    "    # Check if even 1 unit matches, if it does add the comparsion and the sorting to the first_pass_candidates dictionary\n",
    "    this_ks_map = this_com.get_mapped_sorting1()\n",
    "    matches = [x for x in this_ks_map.get_mapped_unit_ids() if x != -1]\n",
    "    if len(matches) == 0: # no matches found\n",
    "        #this is just a sanity check, probably unnecessary\n",
    "        matches2 = [x for x in this_com.get_mapped_sorting2().get_mapped_unit_ids() if x != -1]\n",
    "        if len(matches2) != 0:\n",
    "            #append to funny_business\n",
    "            print(this_key, \" : Funny business!\\n\")\n",
    "            funny_business[this_key] = [this_ksr, this_com]\n",
    "    else:\n",
    "        print(this_key, \" Number of matched units: \", len(matches))\n",
    "        first_pass_candidates[this_key] = [this_ksr, this_com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really low agreement score even for the max value\n",
    "# No matches found from the above iteration\n",
    "max_max = [(a, max_agreement_scores[a].max()) for a in max_agreement_scores]\n",
    "# Need to investigate what's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots()\n",
    "# st  = mclust_res.get_unit_spike_train(8)\n",
    "# ax.plot(st, np.zeros(st.size), '|')\n",
    "# st2 = this_ksr.get_unit_spike_train(34)\n",
    "# ax.plot(st2, np.ones(st2.size), '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ksr_1.get_unit_property_names()\n",
    "# uids = ksr_1.get_unit_ids()\n",
    "# q = [ksr_1.get_unit_property(x, 'KSLabel') for x in uids]\n",
    "# len(ksr_1.get_units_property(property_name='KSLabel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # units matched to ks2 units\n",
    "# ksort1_map = com4.get_mapped_sorting1()\n",
    "# print('Ksort2 units:', ksr_1.get_unit_ids())\n",
    "# print('Ksort2 mapped units:', ksort1_map.get_mapped_unit_ids())\n",
    "\n",
    "# # units matched to msort units\n",
    "# mclust_map = com4.get_mapped_sorting2()\n",
    "# print('Mclust units:', msort.get_unit_ids())\n",
    "# print('Mclust mapped units:', mclust_map.get_mapped_unit_ids())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
